{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9beb830",
   "metadata": {},
   "source": [
    "## RNN is used to generate a sequence of text, such as generating text character by character. \n",
    "\n",
    "- A simple Recurrent Neural Network (RNN) can be used for text data sequence generation in various ways. Here are a few examples:\n",
    "\n",
    "## Character-level Text Generation:\n",
    "\n",
    "### Generate text character by character.\n",
    "Example: Predict the next character in a sequence based on previous characters.\n",
    "- Application: Generating new text in the style of a given text corpus (e.g., generating new Shakespearean text).\n",
    "Word-level Text Generation:\n",
    "\n",
    "#### Generate text word by word.\n",
    "Example: Predict the next word in a sequence based on previous words.\n",
    "- Application: Creating coherent sentences or paragraphs based on a training corpus (e.g., generating news headlines).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6020ad08",
   "metadata": {},
   "source": [
    "### Example 1: Predicting the Next Character in a String"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d2c7b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Generate a sequence of characters\n",
    "alphabet = \"abcdefghijklmnopqrstuvwxyz\"\n",
    "sequence_length = len(alphabet)\n",
    "\n",
    "# Prepare data\n",
    "X = []\n",
    "y = []\n",
    "for i in range(sequence_length - 4):\n",
    "    X.append([ord(char) for char in alphabet[i:i+4]])\n",
    "    y.append(ord(alphabet[i+4]))\n",
    "\n",
    "X = np.array(X).reshape((-1, 4, 1)) / 255.0  # Normalize\n",
    "y = to_categorical(y, num_classes=256)  # One-hot encoding\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae680bc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x15195995a60>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define RNN model\n",
    "model = Sequential()\n",
    "model.add(SimpleRNN(50, activation='relu', input_shape=(4, 1)))\n",
    "model.add(Dense(256, activation='softmax'))\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X, y, epochs=1000, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b087787d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a new sequence\n",
    "input_sequence = np.array([ord(char) for char in \"efgh\"]).reshape((1, 4, 1)) / 255.0\n",
    "prediction = model.predict(input_sequence, verbose=0)\n",
    "predicted_char = chr(np.argmax(prediction))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d502e338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.39607843],\n",
       "        [0.4       ],\n",
       "        [0.40392157],\n",
       "        [0.40784314]]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98679228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Sequence: efgh\n",
      "Next Character Prediction: i\n"
     ]
    }
   ],
   "source": [
    "# Print results\n",
    "print(\"Input Sequence:\", \"efgh\")\n",
    "print(\"Next Character Prediction:\", predicted_char)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96512e45",
   "metadata": {},
   "source": [
    "### Example 2: Generate text word by word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3ddd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "\n",
    "# Example input text\n",
    "text = \"how are you feeling today?\"\n",
    "\n",
    "# Create character mapping\n",
    "chars = sorted(set(text))\n",
    "char_to_idx = {ch: idx for idx, ch in enumerate(chars)}\n",
    "idx_to_char = {idx: ch for idx, ch in enumerate(chars)}\n",
    "num_chars = len(chars)\n",
    "\n",
    "# Prepare input-output pairs for training\n",
    "max_len = 10  # Adjust max_len based on the sequences used for training\n",
    "step = 1\n",
    "sequences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - max_len, step):\n",
    "    sequences.append(text[i:i + max_len])\n",
    "    next_chars.append(text[i + max_len])\n",
    "    \n",
    "# Vectorization\n",
    "X = np.zeros((len(sequences), max_len, num_chars), dtype=np.float32)\n",
    "y = np.zeros((len(sequences), num_chars), dtype=np.float32)\n",
    "for i, sequence in enumerate(sequences):\n",
    "    for t, char in enumerate(sequence):\n",
    "        X[i, t, char_to_idx[char]] = 1.0\n",
    "    y[i, char_to_idx[next_chars[i]]] = 1.0\n",
    "\n",
    "# Build the RNN model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(max_len, num_chars)))\n",
    "model.add(Dense(num_chars, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
    "\n",
    "# Training the model\n",
    "model.fit(X, y, batch_size=1, epochs=100, verbose=2)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(model, seed_text, max_len, num_chars):\n",
    "    generated_text = seed_text\n",
    "    for _ in range(max_len):\n",
    "        x_pred = np.zeros((1, max_len, num_chars), dtype=np.float32)\n",
    "        for t, char in enumerate(seed_text):\n",
    "            x_pred[0, t, char_to_idx[char]] = 1.0\n",
    "        preds = model.predict(x_pred, verbose=0)[0]\n",
    "        next_index = np.random.choice(num_chars, p=preds)\n",
    "        next_char = idx_to_char[next_index]\n",
    "        generated_text += next_char\n",
    "        seed_text = seed_text[1:] + next_char\n",
    "    return generated_text\n",
    "\n",
    "# Generate a sequence\n",
    "generated_sequence = generate_text(model, seed_text=\"hello \", max_len=10, num_chars=num_chars)  # Use max_len consistent with training\n",
    "print(\"Generated Sequence:\")\n",
    "print(generated_sequence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c192aa6",
   "metadata": {},
   "source": [
    "## 3.Example Word sequence Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "695828e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Example text data (replace with your dataset)\n",
    "text_data = [\n",
    "    \"Hi what are you doing today? Any plans\"\n",
    "]\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences using tokenizer\n",
    "input_sequences = []\n",
    "for line in text_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences for equal length input\n",
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create predictors and labels\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "label = tf.keras.utils.to_categorical(label, num_classes=total_words)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(predictors, label, epochs=100, verbose=1)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_index = np.argmax(predicted_probs)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# Generate text\n",
    "generated_text = generate_text(\"Hi Rubi\", 5, model, max_sequence_len)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d0be07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LSTM, Embedding\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Example text data (replace with your dataset)\n",
    "text_data = [\n",
    "    \"The quick brown fox jumps over the lazy dog.\",\n",
    "    \"She sells seashells by the seashore.\",\n",
    "    \"How much wood would a woodchuck chuck if a woodchuck could chuck wood?\"\n",
    "]\n",
    "\n",
    "# Tokenize the text data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_data)\n",
    "total_words = len(tokenizer.word_index) + 1\n",
    "\n",
    "# Create input sequences using tokenizer\n",
    "input_sequences = []\n",
    "for line in text_data:\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)\n",
    "\n",
    "# Pad sequences for equal length input\n",
    "max_sequence_len = max([len(seq) for seq in input_sequences])\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))\n",
    "\n",
    "# Create predictors and labels\n",
    "predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "\n",
    "# Convert labels to categorical one-hot encoding\n",
    "label = tf.keras.utils.to_categorical(label, num_classes=total_words)\n",
    "\n",
    "# Build the model\n",
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 10, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(total_words, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(predictors, label, epochs=100, verbose=1)\n",
    "\n",
    "# Function to generate text\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
    "        predicted_index = np.argmax(predicted_probs)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted_index:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "# User input to generate text\n",
    "user_input = input(\"Enter a starting phrase: \")\n",
    "num_words = int(input(\"Enter number of words to generate: \"))\n",
    "\n",
    "generated_text = generate_text(user_input.lower(), num_words, model, max_sequence_len)\n",
    "print(\"Generated Text:\", generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195fc8ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
